# text_extraction
纯文本爬虫及文本规则提取
## 需求
* 爬去某个外文网站的某些文本文档，网站前缀为https://www.sec.gov/Archives/。完整的URL为网站前缀加上文档middle_sample.csv中列index。比如第一个需要请求的的完整的URL为https://www.sec.gov/Archives/edgar/data/20/0000893220-95-000352.txt
* 获得文本会把文本储存在本地文件夹source中，文件命名方式为文档middle_sample.csv中前六列的字符串用任意复合连接起来，在这里为用了符合“-”。
* 对于每个爬下来的文档，按特定规则把文本中的部分字符串提取出来，并保存到本地文件夹result中，文档命名同上。
* 提取规则为在原文本中最后一次出现特定关键句keyword之前的字符串中再找出第一次出现另一个关键句another keyword后面的所有字符串提取出来。假设在小写文本中第一次出现table的索引位置为 1000，那么在原文本中前 1000个字符里最后一次出现keyword的索引位置为800则把原文本索引为800之后的所有字符抽取出来，记为text2若所有table在小写文档中出现的索引都小于keyword在原文档第一次出现的索引则直接把原文档另存为为新文档。

## 文档说明
* /source/
  - 用于存放原始爬取下来的原始文本。由于前部分没有一个文本符合后面的文本提取规则，因此额外添加一个符合提取规则的文本test.txt作为检验测试效果。
* /result/
  - 用于存放满足提取规则规则且经过规则提取的文本。
* middle_sample.csv
  - 列index :目标URL的后半部分。
  - 前六列 ：作为文档爬取结果的文档命名用。

## 代码说明
* find_tool.py
  - 用于找出文本中出现所有keyword的索引为止，实际上可以用re.findall()
* get_text.py
  - 爬虫程序，由于目前只需获取原文本网站，挺简单的程序
* mian.py
  - 主函数。根据提取规则提取想要的字符串保存成新文本。
* summary.py
  - 把以上的代码汇总成一个脚步
* M_main.m
  - matlab代码。没有爬虫，不过可以用于提取某个特定文本。
